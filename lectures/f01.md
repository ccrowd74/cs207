---
title: Introduction to C
layout: lecture
mathjax: true
---

 - [Computer architecture](#architecture)
  - [Numbers to live by](#numbers)
 - [Compilers, debuggers, and program internals](#tools)
  - [Running a compiler](#compiler)
  - [Running a debugger](#debugger)
 - [Basic C syntax](#syntax)
 - [Pointers](#pointers)
 - [Allocation](#allocation)

<a name='architecture'></a>
## Computer architecture
In its simplest form, your computer looks like this:

![Simple computer]({{site.baseurl}}/lectures/f01/simple_computer_0.png)

Your data is stored in memory, and your CPU executes your programs. When you're surfing the web or writing email, this is a good mental model to use.
Realistically, however, computers are amongst the most complicated devices ever invented, and to understand how programs actually work, we're going to need to go a bit deeper.

Let's start by introducing a program fragment that we can use as a motivating example for talking about different pieces of the computer.
This code is written in C, but it should look familiar enough to any programmer.

```c
...
x = M[0];
y = M[1];
z = x + y;
M[2] = z;
...
```

Processors get work done by executing a series of *instructions*, primitive computational tasks like adding or multiplying two numbers.
These are carried out by a piece of the processor called the arithmetic logic unit, or ALU.
In the earliest days of computing, an ALU would process values directly out of memory, but in modern devices, memory is actually an incredibly long way away relative to the distances inside a CPU.
If an ALU were to compute using data in memory directly, your CPU would be at least 100 times slower than it is now.
Instead, the ALU reads and writes its values to *registers*, which are very small, fast memory locations nearby.

When we run the code fragment above, we can pretend that three basic things happen: first, the values `x`, `y`, and `z` are copied from memory to registers.
Second, the ALU computes the sum and stores it to another register.
Third, the result is copied from a register to memory.
It looks something like this:

![Less simple computer]({{site.baseurl}}/lectures/f01/simple_computer_1.png)

Of course, I said "we can pretend..." because this is all a lie, too.
This is just another, slightly-less-simple model of how computers work.
It's somewhat more accurate, and for some tasks, it's more useful, but it's a long way away from being a complete picture.
In fact, it's difficult to imagine what a complete picture would even look like, because it would involve all five billion transistors.
So in practice, everyone uses a model that is overly simplistic to *some* degree, and the question of how simple depends on the work you'd like to do.

For our purposes, we're going to add a couple more details to our model before we move on.

If you recall from your previous lab, we used a technique called *memoization* to remember the result of function calls.
Memoization is a special form of *caching*.
Caching is a pretty fundamental idea in computer science, and it's used all over.
The basic idea goes like this:

 - Fast memory is usually expensive, and slow memory is usually cheap.
 - Some of your data will be used a lot more often then others.
 - Put frequently-used data in a small, expensive, fast memory.
 - Put rarely-used data in a big, cheap, slow memory.

Modern processors have several types of caches of varying sizes and functions, but they all follow basically the same rules, and they work automatically behind the scenes.
When the ALU needs a piece of data from memory, it is loaded into a register, but a copy is stored in caches along the way.
If we have more values than registers, we have to replace some value.
If we then need to use that value again, instead of going all the way to memory to look it up, we can use the copy stored in cache.

![Even less simple computer]({{site.baseurl}}/lectures/f01/simple_computer_2.png)

This structure of increasingly larger but slower storage is called the *memory hierarchy*, and it is one of the most important things to understand about computer architecture when trying to make your programs fast.

<a name='numbers'></a>
#### Numbers to live by
Registers are "fast", and memory is "slow", but these are relative terms.
What do we really mean?
Every processor is slightly different, but we can give a rough order-of-magnitude.
Modern processors operate at around 2GHz and can run most instructions in a single cycle, which means an add takes about 0.5 nanoseconds.

This idea originally inspired by [Peter Norvig](http://norvig.com/21-days.html#answers) and updated somewhat for 15-year-old numbers.

Task | Approximate latency in log2(cycles) | Same, in cycles
---|---|---
Add two numbers | 0 | 1
Access a register | 0| 1
Access L1 cache [ref](http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf) | 2 | 4
Access L2 cache [ref](http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf) | 4 | 16
Access L3 cache [ref](http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf) | 5 | 32
Access memory | 7 | 128
Access disk [ref](https://en.wikipedia.org/wiki/Hard_disk_drive#Seek_time)| 10 | 1024
Ping a server in LA from NY [ref](https://ipnetwork.bgtmo.ip.att.net/pws/network_delay.html) | 17 | 131072

Take these numbers with a grain of salt: I've rounded them to a close power of two, and they depend heavily on other conditions.
Still, it's useful to keep in mind when estimating the cost of something.

[Back to top &uarr;](#)

<a name='tools'></a>
## Compilers, debuggers, and program internals

CPU instructions look nothing like programs humans write.
In python, adding two numbers is simply `a+b`, but a processor needs to see something like `0x4801d0`.
How does one become the other?

In a high-level scripting language like python, this happens through an *interpreter*.
When you run `python my_script.py`, the `python` part is the interpreter.
It reads in your file and starts going line by line, digesting the text of your script and trying to execute the right instructions.
For instance, when it sees the string `a+b`, it looks into the data structure which contains the current environment frame (as we saw in previous lectures) to find the current values of `a` and `b`, and then it executes the `operator.add` function on these two values.

Of course, a natural question to ask is, "who interprets the interpreter?"
*Something* had to be responsible for the instructions to lookup `a` in an environment frame, and for producing that frame in the first place.
So what is it?

The answer is that `python` is written in C, a low-level programming language, and C code can be translated into machine instructions using a *compiler*.
A compiler is a program that reads programs in and writes binary executable files out.
On Windows, any `.exe` file is one of these binary executables.
On any Unix-like system (Linux or OS X included), binary executables aren't required to have file extensions, but most programs you run from the command line are examples.

<a name='compiler'></a>
### Running a compiler
In the very first lab, we asked you to install `gcc`, a C compiler.
Now we'll learn what it does and how to use it.

First, let's start with a simple C program.
For now, it's not important what it is, just that it is a C program.

```c
#include <stdint.h>
#include <stdio.h>

int main(int argc, char **argv)
{
  int64_t a=1, b=2, c;
  c = a+b;
  printf("c=%ld\n", c);
  return 0;
}
```

Let's save this file as `add_two.c` and compile it using `gcc`:

```
$ gcc -o add_two add_two.c
```

This command takes the C source file `add_two.c` and produces the binary executable `add_two`.
On Unix-like systems, arguments to programs which start with `-` or `--` are called "flags" and are typically used to modify the behavior of a program.
For instance, running `python --version` was used to print the version of the python program you were using, instead of to run a script.
Flags are different for every program, but many are named similarly by convention.
For `gcc`, the `-o` flag lets you specify the name of the output file (flags are usually given mnemonic names), in this case `add_two`.
The `add_two` is an argument to the `-o` flag, whereas `add_two.c` is an argument passed directly to the program.

To convince ourselves that this work, lets run the program.

```
$ ./add_two
c=3
```

If this were python, we would've had to run the python interpreter.
Here, our binary executable file contains processor instructions, so we can run it directly.

<a name='debugger'></a>
### Running a debugger

Python and many other high-level languages have "REPL"s, or read-eval-print loops.
This is easy to see by running `python` with no arguments:

```
$ python
Python 3.5.1 |Anaconda 2.4.1 (64-bit)| (default, Dec  7 2015, 11:16:01)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
```

The shell prompt (`$`) has been replaced with a python prompt (`>>>`), which signifies that anything you type will be read and evaluated by the python interpreter and the result printed for you.
REPLs only truly work in interpreted languages, because they can operate on program fragments.
A compiler doesn't actually evaluate the source code; it only translates it into machine instructions.
As a result, low-level languages cannot operate within a REPL.

In order to understand the behavior of non-trivial programs, it is incredibly useful to inspect and manipulate the internal state of a program.
With an interpreted language, this is easy, since the interpreter has direct access to this state, and we can query it directly.
In compiled languages, we rely on a tool called a *debugger*.

A debugger is a program which runs alongside your program and controls when and how your program's instructions execute.
It can tell your program to start or stop running, inspect and modify your program's memory, and even translate this memory back into the names you gave it in the source code.

Running a debugger actually requires two steps:

First, we need to compile our program with the `-g` flag.
This flag tells the compiler to save a list of "debugging symbols", which is a table of mappings between specific instructions or memory locations and variable names from your source code file.
On linux systems, this information is actually stored inside the binary executable, and you can see the space taken up by it by looking at the file size:

First let's compile our program without symbols and check it's size.
(For the curious, you can investigate the `stat` command by typing `man stat`, which will give you a manual page entry for it.)

```
$ gcc -o add_two_bare add_two.c
$ stat -c '%s' add_two_bare
8555
```

So the `add_two_bare` program takes up 8555 bytes. Let's look at the program with debugging symbols now:

```
$ gcc -g -o add_two_debug add_two.c
$ stat -c '%s' add_two_debug
9755
```

9755 bytes. So the debugging symbols for this program take up an extra 1200 bytes.
In general, most programs that are distributed to the public do not have debugging symbols in them, and the extra space is one reason.

The second step is to actually run the debugger on your program.
In this class, we will be using `gdb` as our debugger, but most operate in a very similar way.
Start gdb by running it with your binary (with debugging symbols) as an argument:

```
$ gdb add_two_debug
GNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1
Copyright (C) 2014 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from add_two_debug...done.
(gdb)
```

The first thing you'll notice is that you have a REPL.
`gdb` feels somewhat like an interpreter because you can give it commands and see results printed out for you without compiling or modifying your program.
In fact, `gdb` is a sophisticated window into the state of *another program*, in this case, your `add_two_debug` program.

Let's tell `gdb` to start executing your program.

```
(gdb) run
Starting program: /home/cs207/shared/f01/add_two_debug
c=3
[Inferior 1 (process 3574) exited normally]
```

Okay, so the program started, printed its output, and finished.
This is well and good, but we wanted to see the internal state of the program.
To do that, we'll need to set a *breakpoint*.
A breakpoint is simply a location in your program where you would like to freeze its execution.
It's easier to see in action:

```
(gdb) break 8
Breakpoint 1 at 0x40054c: file add_two.c, line 8.
(gdb) run
Starting program: /home/cs207/shared/f01/add_two_debug

Breakpoint 1, main (argc=1, argv=0x7fffffffec08) at add_two.c:8
8	  c = a+b;
(gdb)
```

`gdb` tells us that it has started your program and then stopped it mid-execution.
At the beginning of this section, we stated that what you write in a program is not what the machine executes, so how does `gdb` know where to stop the program?
The answer is in the debugging symbols that you compiled into your binary executable.
When you run `break 8` in `gdb`, it looks up that location and translates it into a location in the binary file.
Then it asks the processor to stop the program when it reaches that location.
The result is that we have a half-executed program we can manipulate.

In fact, `gdb` can also show us *exactly* what the processor sees.
This is called "disassembling": translating machine instructions into a language we call "assembly language", which is just a human-readable form of machine instructions.

```
(gdb) disassemble
Dump of assembler code for function main:
   0x000000000040052d <+0>:	push   %rbp
   0x000000000040052e <+1>:	mov    %rsp,%rbp
   0x0000000000400531 <+4>:	sub    $0x30,%rsp
   0x0000000000400535 <+8>:	mov    %edi,-0x24(%rbp)
   0x0000000000400538 <+11>:	mov    %rsi,-0x30(%rbp)
   0x000000000040053c <+15>:	movq   $0x1,-0x18(%rbp)
   0x0000000000400544 <+23>:	movq   $0x2,-0x10(%rbp)
=> 0x000000000040054c <+31>:	mov    -0x10(%rbp),%rax
   0x0000000000400550 <+35>:	mov    -0x18(%rbp),%rdx
   0x0000000000400554 <+39>:	add    %rdx,%rax
   0x0000000000400557 <+42>:	mov    %rax,-0x8(%rbp)
   0x000000000040055b <+46>:	mov    -0x8(%rbp),%rax
   0x000000000040055f <+50>:	mov    %rax,%rsi
   0x0000000000400562 <+53>:	mov    $0x400604,%edi
   0x0000000000400567 <+58>:	mov    $0x0,%eax
   0x000000000040056c <+63>:	callq  0x400410 <printf@plt>
   0x0000000000400571 <+68>:	mov    $0x0,%eax
   0x0000000000400576 <+73>:	leaveq
   0x0000000000400577 <+74>:	retq
End of assembler dump.
(gdb)
```

You're looking at the machine representation of your executable.
You don't need to understand the meaning of these instructions, but there's some fun points to observe.
First, the `=>` represents the instruction that the debugger froze the program just before executing.
All the instructions above that point have already been executed, and if you let the program run again, all the instructions below will be run afterwards.
You should even be able to spot a couple of features of your program.
The `add %rdx, %rax` instruction is what actually adds our two numbers, and the `callq 0x400410 <printf@plt>` is the function call to `printf`.

Before we move on, let's investigate two more features of the debugger: stepping through instructions and printing the call stack.

While `gdb` isn't a REPL, it can behave in a similar fashion in some cases.
Specifically, you can run your program step-by-step and see the results.
We'll need a couple commands for this:

 - `list` prints your source code. This is a handy function for remembering what your program looked like without having to flip back and forth between two programs.
 - `print` works just like it sounds: it prints the result of some C expression. Fun fact: `gdb` has a lightweight interpreter built-in which let's you evaluate simple C expressions just for this scenario.
 - `next` moves one line forward in your program. In reality, this might mean more than one instruction gets executed, because of the difference between source code statements and machine instructions.
 - `backtrace` prints the *call stack*. This is very similar to the environment frames we looked at earlier, and we'll revisit exactly what this means later.
 - `continue` unfreezes the program and lets it run until it either finishes or hits another breakpoint.
 - `quit` does what it says.

```
(gdb) print c
$2 = 1
(gdb) print b
$3 = 2
(gdb) print c
$4 = 0
(gdb) next
10	  printf("c=%ld\n", c);
(gdb) print c
$5 = 3
(gdb) backtrace
#0  main (argc=1, argv=0x7fffffffec08) at add_two.c:10
(gdb) continue
Continuing.
c=3
[Inferior 1 (process 3578) exited normally]
(gdb) quit
```

The debugger is an incredibly powerful tool, and you'll want to get familiar with it when you start writing in C.


<a name='syntax'></a>
## Basic C syntax
Most languages have similar syntax for expressions. `a+b` works just like you would expect in python.

### Static types
(compile-time vs run-time, bytes vs. objects)

### Header files

<a name='pointers'></a>
## Pointers
(addrs in mem, syntax)

### Strings and arrays
(contiguous allocation, no frills)

### Pointer casting
("reinterpreting the data as x")

<a name='allocation'></a>
## Allocation

### Program segments

### The stack and the heap

### Malloc and free
