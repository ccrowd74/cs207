---
title: Introduction to C
layout: lecture
mathjax: true
---

 - [Computer architecture](#architecture)
  - [Numbers to live by](#numbers)
 - [Compilers, debuggers, and program internals](#tools)
  - [Running a compiler](#compiler)
  - [Running a debugger](#debugger)
 - [Basic C syntax](#syntax)
  - [Static types](#types)
 - [Pointers](#pointers)
  - [Strings and arrays](#arrays)
  - [Pointer casting](#casting)

<a name='architecture'></a>
## Computer architecture
In its simplest form, your computer looks like this:

![Simple computer]({{site.baseurl}}/lectures/f01/simple_computer_0.png)

Your data is stored in memory, and your CPU executes your programs. When you're surfing the web or writing email, this is a good mental model to use.
Realistically, however, computers are amongst the most complicated devices ever invented, and to understand how programs actually work, we're going to need to go a bit deeper.

Let's start by introducing a program fragment that we can use as a motivating example for talking about different pieces of the computer.
This code is written in C, but it should look familiar enough to any programmer.

```c
...
x = M[0];
y = M[1];
z = x + y;
M[2] = z;
...
```

Processors get work done by executing a series of *instructions*, primitive computational tasks like adding or multiplying two numbers.
These are carried out by a piece of the processor called the arithmetic logic unit, or ALU.
In the earliest days of computing, an ALU would process values directly out of memory, but in modern devices, memory is actually an incredibly long way away relative to the distances inside a CPU.
If an ALU were to compute using data in memory directly, your CPU would be at least 100 times slower than it is now.
Instead, the ALU reads and writes its values to *registers*, which are very small, fast memory locations nearby.

When we run the code fragment above, we can pretend that three basic things happen: first, the values `x`, `y`, and `z` are copied from memory to registers.
Second, the ALU computes the sum and stores it to another register.
Third, the result is copied from a register to memory.
It looks something like this:

![Less simple computer]({{site.baseurl}}/lectures/f01/simple_computer_1.png)

Of course, I said "we can pretend..." because this is all a lie, too.
This is just another, slightly-less-simple model of how computers work.
It's somewhat more accurate, and for some tasks, it's more useful, but it's a long way away from being a complete picture.
In fact, it's difficult to imagine what a complete picture would even look like, because it would involve all five billion transistors.
So in practice, everyone uses a model that is overly simplistic to *some* degree, and the question of how simple depends on the work you'd like to do.

For our purposes, we're going to add a couple more details to our model before we move on.

If you recall from your previous lab, we used a technique called *memoization* to remember the result of function calls.
Memoization is a special form of *caching*.
Caching is a pretty fundamental idea in computer science, and it's used all over.
The basic idea goes like this:

 - Fast memory is usually expensive, and slow memory is usually cheap.
 - Some of your data will be used a lot more often then others.
 - Put frequently-used data in a small, expensive, fast memory.
 - Put rarely-used data in a big, cheap, slow memory.

Modern processors have several types of caches of varying sizes and functions, but they all follow basically the same rules, and they work automatically behind the scenes.
When the ALU needs a piece of data from memory, it is loaded into a register, but a copy is stored in caches along the way.
If we have more values than registers, we have to replace some value.
If we then need to use that value again, instead of going all the way to memory to look it up, we can use the copy stored in cache.

![Even less simple computer]({{site.baseurl}}/lectures/f01/simple_computer_2.png)

This structure of increasingly larger but slower storage is called the *memory hierarchy*, and it is one of the most important things to understand about computer architecture when trying to make your programs fast.

<a name='numbers'></a>
### Numbers to live by
Registers are "fast", and memory is "slow", but these are relative terms.
What do we really mean?
Every processor is slightly different, but we can give a rough order-of-magnitude.
Modern processors operate at around 2GHz and can run most instructions in a single cycle, which means an add takes about 0.5 nanoseconds.

This idea originally inspired by [Peter Norvig](http://norvig.com/21-days.html#answers) and updated somewhat for 15-year-old numbers.

Task | Approximate latency in log2(cycles) | Same, in cycles
---|---|---
Add two numbers | 0 | 1
Access a register | 0| 1
Access L1 cache [ref](http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf) | 2 | 4
Access L2 cache [ref](http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf) | 4 | 16
Access L3 cache [ref](http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf) | 5 | 32
Access memory | 7 | 128
Access disk [ref](https://en.wikipedia.org/wiki/Hard_disk_drive#Seek_time)| 10 | 1024
Ping a server in LA from NY [ref](https://ipnetwork.bgtmo.ip.att.net/pws/network_delay.html) | 17 | 131072

Take these numbers with a grain of salt: I've rounded them to a close power of two, and they depend heavily on other conditions.
Still, it's useful to keep in mind when estimating the cost of something.

[Back to top &uarr;](#)

<a name='tools'></a>
## Compilers, debuggers, and program internals

CPU instructions look nothing like programs humans write.
In Python, adding two numbers is simply `a+b`, but a processor needs to see something like `0x4801d0`.
How does one become the other?

In a high-level scripting language like Python, this happens through an *interpreter*.
When you run `python my_script.py`, the `python` part is the interpreter.
It reads in your file and starts going line by line, digesting the text of your script and trying to execute the right instructions.
For instance, when it sees the string `a+b`, it looks into the data structure which contains the current environment frame (as we saw in previous lectures) to find the current values of `a` and `b`, and then it executes the `operator.add` function on these two values.

Of course, a natural question to ask is, "who interprets the interpreter?"
*Something* had to be responsible for the instructions to lookup `a` in an environment frame, and for producing that frame in the first place.
So what is it?

The answer is that `python` is written in C, a low-level programming language, and C code can be translated into machine instructions using a *compiler*.
A compiler is a program that reads programs in and writes binary executable files out.
On Windows, any `.exe` file is one of these binary executables.
On any Unix-like system (Linux or OS X included), binary executables aren't required to have file extensions, but most programs you run from the command line are examples.

[Back to top &uarr;](#)

<a name='compiler'></a>
### Running a compiler
In the very first lab, we asked you to install `gcc`, a C compiler.
Now we'll learn what it does and how to use it.

First, let's start with a simple C program.
For now, it's not important what it is, just that it is a C program.

```c
#include <stdint.h>
#include <stdio.h>

int main(int argc, char **argv)
{
  int64_t a=1, b=2, c;
  c = a+b;
  printf("c=%ld\n", c);
  return 0;
}
```

Let's save this file as `add_two.c` and compile it using `gcc`:

```
$ gcc -o add_two add_two.c
```

This command takes the C source file `add_two.c` and produces the binary executable `add_two`.
On Unix-like systems, arguments to programs which start with `-` or `--` are called "flags" and are typically used to modify the behavior of a program.
For instance, running `python --version` was used to print the version of the Python program you were using, instead of to run a script.
Flags are different for every program, but many are named similarly by convention.
For `gcc`, the `-o` flag lets you specify the name of the output file (flags are usually given mnemonic names), in this case `add_two`.
The `add_two` is an argument to the `-o` flag, whereas `add_two.c` is an argument passed directly to the program.

To convince ourselves that this work, lets run the program.

```
$ ./add_two
c=3
```

If this were Python, we would've had to run the Python interpreter.
Here, our binary executable file contains processor instructions, so we can run it directly.

[Back to top &uarr;](#)

<a name='debugger'></a>
### Running a debugger

Python and many other high-level languages have "REPL"s, or read-eval-print loops.
This is easy to see by running `python` with no arguments:

```
$ python
Python 3.5.1 |Anaconda 2.4.1 (64-bit)| (default, Dec  7 2015, 11:16:01)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
```

The shell prompt (`$`) has been replaced with a Python prompt (`>>>`), which signifies that anything you type will be read and evaluated by the Python interpreter and the result printed for you.
REPLs only truly work in interpreted languages, because they can operate on program fragments.
A compiler doesn't actually evaluate the source code; it only translates it into machine instructions.
As a result, low-level languages cannot operate within a REPL.

In order to understand the behavior of non-trivial programs, it is incredibly useful to inspect and manipulate the internal state of a program.
With an interpreted language, this is easy, since the interpreter has direct access to this state, and we can query it directly.
In compiled languages, we rely on a tool called a *debugger*.

A debugger is a program which runs alongside your program and controls when and how your program's instructions execute.
It can tell your program to start or stop running, inspect and modify your program's memory, and even translate this memory back into the names you gave it in the source code.

Running a debugger actually requires two steps:

First, we need to compile our program with the `-g` flag.
This flag tells the compiler to save a list of "debugging symbols", which is a table of mappings between specific instructions or memory locations and variable names from your source code file.
On linux systems, this information is actually stored inside the binary executable, and you can see the space taken up by it by looking at the file size:

First let's compile our program without symbols and check it's size.
(For the curious, you can investigate the `stat` command by typing `man stat`, which will give you a manual page entry for it.)

```
$ gcc -o add_two_bare add_two.c
$ stat -c '%s' add_two_bare
8555
```

So the `add_two_bare` program takes up 8555 bytes. Let's look at the program with debugging symbols now:

```
$ gcc -g -o add_two_debug add_two.c
$ stat -c '%s' add_two_debug
9755
```

9755 bytes. So the debugging symbols for this program take up an extra 1200 bytes.
In general, most programs that are distributed to the public do not have debugging symbols in them, and the extra space is one reason.

The second step is to actually run the debugger on your program.
In this class, we will be using `gdb` as our debugger, but most operate in a very similar way.
Start gdb by running it with your binary (with debugging symbols) as an argument:

```
$ gdb add_two_debug
GNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1
Copyright (C) 2014 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from add_two_debug...done.
(gdb)
```

The first thing you'll notice is that you have a REPL.
`gdb` feels somewhat like an interpreter because you can give it commands and see results printed out for you without compiling or modifying your program.
In fact, `gdb` is a sophisticated window into the state of *another program*, in this case, your `add_two_debug` program.

Let's tell `gdb` to start executing your program.

```
(gdb) run
Starting program: /home/cs207/shared/f01/add_two_debug
c=3
[Inferior 1 (process 3574) exited normally]
```

Okay, so the program started, printed its output, and finished.
This is well and good, but we wanted to see the internal state of the program.
To do that, we'll need to set a *breakpoint*.
A breakpoint is simply a location in your program where you would like to freeze its execution.
It's easier to see in action:

```
(gdb) break 8
Breakpoint 1 at 0x40054c: file add_two.c, line 8.
(gdb) run
Starting program: /home/cs207/shared/f01/add_two_debug

Breakpoint 1, main (argc=1, argv=0x7fffffffec08) at add_two.c:8
8	  c = a+b;
(gdb)
```

`gdb` tells us that it has started your program and then stopped it mid-execution.
At the beginning of this section, we stated that what you write in a program is not what the machine executes, so how does `gdb` know where to stop the program?
The answer is in the debugging symbols that you compiled into your binary executable.
When you run `break 8` in `gdb`, it looks up that location and translates it into a location in the binary file.
Then it asks the processor to stop the program when it reaches that location.
The result is that we have a half-executed program we can manipulate.

In fact, `gdb` can also show us *exactly* what the processor sees.
This is called "disassembling": translating machine instructions into a language we call "assembly language", which is just a human-readable form of machine instructions.

```
(gdb) disassemble
Dump of assembler code for function main:
   0x000000000040052d <+0>:	push   %rbp
   0x000000000040052e <+1>:	mov    %rsp,%rbp
   0x0000000000400531 <+4>:	sub    $0x30,%rsp
   0x0000000000400535 <+8>:	mov    %edi,-0x24(%rbp)
   0x0000000000400538 <+11>:	mov    %rsi,-0x30(%rbp)
   0x000000000040053c <+15>:	movq   $0x1,-0x18(%rbp)
   0x0000000000400544 <+23>:	movq   $0x2,-0x10(%rbp)
=> 0x000000000040054c <+31>:	mov    -0x10(%rbp),%rax
   0x0000000000400550 <+35>:	mov    -0x18(%rbp),%rdx
   0x0000000000400554 <+39>:	add    %rdx,%rax
   0x0000000000400557 <+42>:	mov    %rax,-0x8(%rbp)
   0x000000000040055b <+46>:	mov    -0x8(%rbp),%rax
   0x000000000040055f <+50>:	mov    %rax,%rsi
   0x0000000000400562 <+53>:	mov    $0x400604,%edi
   0x0000000000400567 <+58>:	mov    $0x0,%eax
   0x000000000040056c <+63>:	callq  0x400410 <printf@plt>
   0x0000000000400571 <+68>:	mov    $0x0,%eax
   0x0000000000400576 <+73>:	leaveq
   0x0000000000400577 <+74>:	retq
End of assembler dump.
(gdb)
```

You're looking at the machine representation of your executable.
You don't need to understand the meaning of these instructions, but there's some fun points to observe.
First, the `=>` represents the instruction that the debugger froze the program just before executing.
All the instructions above that point have already been executed, and if you let the program run again, all the instructions below will be run afterwards.
You should even be able to spot a couple of features of your program.
The `add %rdx, %rax` instruction is what actually adds our two numbers, and the `callq 0x400410 <printf@plt>` is the function call to `printf`.

Before we move on, let's investigate two more features of the debugger: stepping through instructions and printing the call stack.

While `gdb` isn't a REPL, it can behave in a similar fashion in some cases.
Specifically, you can run your program step-by-step and see the results.
We'll need a couple commands for this:

 - `list` prints your source code. This is a handy function for remembering what your program looked like without having to flip back and forth between two programs.
 - `print` works just like it sounds: it prints the result of some C expression. Fun fact: `gdb` has a lightweight interpreter built-in which let's you evaluate simple C expressions just for this scenario.
 - `next` moves one line forward in your program. In reality, this might mean more than one instruction gets executed, because of the difference between source code statements and machine instructions.
 - `backtrace` prints the *call stack*. This is very similar to the environment frames we looked at earlier, and we'll revisit exactly what this means later.
 - `continue` unfreezes the program and lets it run until it either finishes or hits another breakpoint.
 - `quit` does what it says.

```
(gdb) print c
$2 = 1
(gdb) print b
$3 = 2
(gdb) print c
$4 = 0
(gdb) next
10	  printf("c=%ld\n", c);
(gdb) print c
$5 = 3
(gdb) backtrace
#0  main (argc=1, argv=0x7fffffffec08) at add_two.c:10
(gdb) continue
Continuing.
c=3
[Inferior 1 (process 3578) exited normally]
(gdb) quit
```

The debugger is an incredibly powerful tool, and you'll want to get familiar with it when you start writing in C.

[Back to top &uarr;](#)

<a name='syntax'></a>
## Basic C syntax

So if this was an introduction to C, why are we spending so much time on the structure of processors and tools?
The purpose of low-level programming languages is to control the behavior of a computer to a very fine level of detail.
For some programming tasks (like building an operating system or high-performance network library), it's necessary to specify exactly what needs to get done, mostly for performance and space reasons.
This means that learning how to program is pretty much the same as learning how a computer operates at its lowest levels.
The syntax is almost an afterthought.

Of course, we still need to *use* that syntax, so let's get familiar with C.

We'll start with the building blocks:

**Expressions**

"Expression" is a term for something that can produce a value.
`1`, `x`, `((3+a)*4)`, `sin(2*M_PI)`, and `"a string"` are all examples of expressions.
Expressions can be combined to form other expressions.

**Statements**
Statements carry out some action, and in C, they must end with a semicolon.
`int a;`, `x = 2+y;`, and `return 0;` are all examples of statements.
It's important to understand that statements do not produce a value and cannot be used in place of expressions.
For instance, `a + (x = 2*y;)` is not valid C.
Confusingly, assignment statements are actually expressions in C, which means `a + (x = 2*y)` (no semicolon) *is* valid C.
The value of an assignment expression is the value it assigned, so `(x = 2*y)` would have a value of whatever got assigned to `x`.

**Blocks**
Blocks are groups of zero or more statements, similar to a group of similarly-indented statements in Python.
Normally, blocks are surrounded by braces `{` and `}`.
In C, a variable defined inside a block is only valid for inside that block.
It cannot be used outside, ever.

Let's look at an example fragment from a C program:

```c
// Comments can be written like this.
/* or
   like
   this. */
{ // Start of block 1
  if (x == y) { // Start of block 2
    int a;
    a = x*x;
    printf("x squared: %d\n", a);
  } // End of block 2
  else
  { // Start of block 3
    int b;
    b = x*y;
    printf("x times y: %d\n", b);
  } // End of block 3
  // Neither a or b can be referenced here.
} // End of block 1
```

[Back to top &uarr;](#)

<a name='types'></a>
### Static types
One major difference between Python and C is the type system.
C is a *statically typed* language, which means that you must specify the type of every variable you declare before you compile the program.
Contrast this to Python, in which types are sometimes not known until you actually run the program.
Consider this fragment in Python:

```python
def func(x, y):
  return x + y

print func(1, 2)
print func(1.2, 2.3)
print func(1, 2.3)
```

All three versions of this function just work like you'd expect.
The Python interpreter automatically assigns integer and floating point types to the function arguments as necessary, so `func(1,2)` returns an integer and both  `func(1.2, 2.3)` `func(1, 2.3)` return a floating point number.
C requires explicit type declarations for every variable and function return value.
So the equivalent C fragment would be:

```c
int func0(int x, int y) {
  return x + y;
}
float func1(float x, float y) {
  return x + y;
}
float func2(int x, float y) {
  return x + y;
}

printf("%d\n", func0(1, 2));
printf("%f\n", func1(1.2, 2.3));
printf("%f\n", func2(1, 2.3));
```

Static typing might seem like a headache, but it provides several advantages:

 - Type errors can be detected at compile time. In Python, if you pass a string to a `sqrt` function, it raises a `TypeError` exception.
Because this bug won't be detected until the program runs, you could be hours into a simulation before it triggers and brings down your program.
In C, this kind of bug can often be caught when you compile the program, because the compile knows the types of variables and can reason about them.

 - Memory efficiency. We'll talk more about allocation in a bit, but the short story is that because the C compiler knows if you're defining an array of a million characters or a million strings, it can efficiently make space for your variables in memory.
In Python, many objects, lists and dicts for instance, are agnostic to the types of their arguments, which means they must rely on indirect references to get the actual values.
This is the name-pointing-to-value behavior you saw in the first lecture.

 - Better performance. Compilers transform code significantly to make it faster.
When a compiler knows more information about the code, it can often do a better job of producing a fast binary executable.

C also has a much wider (and stricter) set of types than Python.
For instance, although we specified a variable as an `int` above, this doesn't just mean any integer&mdash;it means a signed, 64-bit integer.
C also lets you specify a variety of other types of integers.

Type | Meaning for ILP64 compilers (most Unix-like systems)
---|---
char | 8-bit signed integer; also used for storing ASCII characters
short | 16-bit signed integer
int | 64-bit signed integer
long | 64-bit signed integer
unsigned char | unsigned 8-bit integer
unsigned short | unsigned 16-bit integer
unsigned int | unsigned 64-bit integer
unsigned long | unsigned 64-bit integer
uint8_t | unsigned 8-bit integer
int32_t | signed 32-bit integer
[u]int[width]_t | signed and unsigned versions for width={8,16,32,64}
float | 32-bit IEEE754-compliant floating point number
double | 64-bit IEEE754-compliant floating point number

Observant readers might notice the conspicuous absence of human names for 32-bit integers.
This is a historical artifact: int the past, `char`, `short`, `int`, and `long` were often 8, 16, 32, and 64 bits wide, respectively.
Because many C codes use `int` by default whenever they don't care so much about the type, the size of an `int` matters.
When mainstream processors shifted to native 64 bits words in the early 2000's, some compiler writers decided that a 64-bit integer was more appropriate than a 32-bit integer most of the time, so they changed the definition of `int` to be a 64-bit integer.
This convention is called "ILP64" for "integer-long-pointer 64", which means that those three types are 64 bits wide.
A competing standard, "LP64", where `int` was kept at 32 bits is still used by Microsoft Windows compilers.

[Back to top &uarr;](#)

<a name='pointers'></a>
## Pointers
C also has one other type feature which distinguishes it from most high-level languages: pointers.
A pointer is essentially an integer type that contains the address of some location in memory.
Pointers are both your best friend and your worst enemy.
They are incredibly powerful, and as such, they give you the power to shoot yourself in the foot.

**Declaring pointers**

In Python, we could talk about references and name bindings and frames, but the discussion was always a little abstract: the value of some variable was stored "somewhere" and managed for you.
In C, you know exactly where everything is in memory, because you have to manage it yourself.
For instance, let's say that you have a 64-bit integer:

```c
int64_t x;
```

That integer is stored somewhere, and in C, you can get its location by using the `&` operator:

```c
p = &x;
```

`p` now has the value of the memory address of the variable `x`.
Remember though, in C, everything has to be declared with a type.
So how do we declare `p`?
As a pointer:

```c
int64_t x;
int64_t *p;
p = &x;
```

When used in a type declaration, the `*` operator says that `p` is a pointer to whatever type surrounds it.
This is where things get a little confusing.
C has some complicated rules for specifying types, largely because specifying types can be hard.
What if you want a pointer to a pointer to an integer? `int **x;`, which can also be thought of as `((int *) *)x;`.
Type declarations have precedence rules just like everything else.
But why stop there?
C lets you declare types of functions, too, so we can ask for a pointer to a function which returns a pointer to an integer and takes a pointer to a float as an argument: `(int *)(*func)(double *)`.
And down the rabbit hole you go.

Type specifications take some practice, and you'll need some time to get comfortable with them.
The most important thing is to understand what type you're actually trying to create; once you've got that, experimentation and a generous helping of parentheses will usually get the job done.

**Dereferencing pointers**

So now that we have a pointer, what do we do with it?
The most natural thing to do is get the value it points at.
Take our example from before, and let's assign a value to `x`:

```c
int64_t x;
int64_t *p;
p = &x;
x = 10;
```

We gave `p` the address of `x` using the `&` operator, and now we need the dual of that: a way to get the value of something given its address.
That's also the `*` operator, just like in a pointer type declaration.
We can use it like this:

```c
int64_t x;
int64_t *p;
p = &x;
x = 10;
printf("x is %d\n", *p );
```

This functionality is actually more powerful than it seems at first, and we'll start to see why in the next couple sections.

[Back to top &uarr;](#)

<a name='arrays'></a>
### Strings and arrays
In Python, if you create an array of integers `[1,2,3]`, you can happily add, modify, or remove elements from that array.
But ultimately, those values must be stored *somewhere* in memory.
If you add an element to an array, where does it get stored?
In C, the programmer is the one that controls this.
Specifically, although C technically provides strings and array types, in reality both are just a thin wrapper around pointers.

**Arrays**

For instance, statically declaring an array in C looks like this:

```c
int arr[10];
```

There are two things you should notice right away:

First, the length of the array is specified up front at compile time.
This *cannot* be changed.
This sounds outrageous: how do you add an element?
The answer is, you don't, and (surprisingly) neither does Python.
In reality, an array takes up *contiguous* space in memory.
One element is placed immediately after another.
But what happens if you create two arrays?
Do we put them next to each other?
If so, we cannot ever add an element.
If we choose to place them apart, then (a) we waste space, but (b) there is still a finite number of memory elements between them, which means we cannot grow the array arbitrarily.

The solution is that modifying arrays is equivalent to creating a new array of larger size and copying all the elements over to it.
There are some caveats to this statement, but the essence is true.
Like all low-level languages, C exposes much of the underlying hardware behavior to the programmer, for better or worse.

The second thing to notice about our array declaration is that it has a type associated with it: `int`.
This is the type of each element, which *must be homogenous*.
Unlike Python, C arrays cannot have mixed elements.
This is also due to storage: if we're going to place 10 elements in memory, the compiler needs to know how many bytes to save ahead of time.

Finally, it's important to understand that even though we used special syntax to declare `arr`, it is actually just a pointer to the start of the array.
Thus, if we do this:

```c
int *p;
int a[10];

p = &( a[0] ); // get the address of the first element of the array

printf("%x\n", p);
printf("%x\n", a);
```

we can see that both `a` and `p` hold the same address.
Arrays are just fancy syntax for allocating space and returning a pointer.

**Strings**

Strings in C are not that different.
The string type in C is actually `char *`, which means that strings are *literally* just pointers to characters (recall that a `char` is a signed, one byte integer in C).
The only difference is C strings are, by convention, handled somewhat differently.
Specifically, a C string is an array where the first `n-1` elements are characters in the string and the last array element is a `0`.
So these two statements are effectively identical in C:

```c
char *s0 = "hello";
char s1[6] = {'h','e','l','l','o',0};
```

[Back to top &uarr;](#)

<a name='casting'></a>
### Pointer casting
The last thing major thing to understand about pointers is that the types are a convenience for the compiler, not a law.
In other words, an address is an address, regardless of what it points to.
Let's say you have the following code:

```c
int64_t x = 10;
int32_t y = 11;
int8_t *p;
```

The types of `x` and `y` are 64- and 32-bit integers, which means they take up that much space in memory.
But `10` and `11` are small numbers, and in 2's complement representation (which is how numbers are stored in most computers), these end up being a large number of 0's followed by a couple of 1's.
So in actuality, the high-order 7 bytes of `x` and the high-order 3 bytes of `y` are all zero.
So, perhaps surprisingly, this is valid C code:

```c
int64_t x = 10;
int32_t y = 11;
int8_t *p;
p = (int8_t *)(&x); // *cast* &x to a pointer to an int8_t
printf("x as int8_t: %d\n", *p );
p = (int8_t *)(&y); // *cast* &y to a pointer to an int8_t
printf("y as int8_t: %d\n", *p );
```

This is called pointer *casting*, and it is basically equivalent to "reinterpreting" the bits pointed to by a value.
You have to be careful with these operations: when you cast a pointer, the compiler basically trusts that you know what you're doing, regardless of whether that's true or not.
For instance, this is *not* safe to do:

```c
int8_t x = 10;
int64_t *p;
p = (int64_t *)(&x); // *cast* &x to a pointer to an int64_t
printf("x as an int64_t: %d\n", *p);
```

Why? Because `x` only has one byte of valid data at its memory location.
When we reinterpret the memory location as a 64-bit integer, we look at 8 bytes of data.
This means that when we dereference `p`, we read the 1 byte of `x` and 7 bytes of uninitialized memory, which could be anything.
The moral of the story: bytes are just bytes, so understand what is actually in memory before using your pointers.

[Back to top &uarr;](#)
